{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "device='cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ],
   "id": "fbc7e72cb085e14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Divide the training set and the test set",
   "id": "ebb477da6ce4730e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_suzhou=pd.read_excel(\"./data/P1.xlsx\")\n",
    "df_suzhou['日期'] = pd.to_datetime(df_suzhou['日期'])\n",
    "X1_suzhou=df_suzhou.drop(columns=['平均负荷','碳排放强度', '日期','机组'])\n",
    "y1_suzhou=df_suzhou['碳排放强度']\n",
    "\n",
    "df_maanshan=pd.read_excel(\"./data/P3.xlsx\")\n",
    "df_maanshan['日期'] = pd.to_datetime(df_maanshan['日期'])\n",
    "\n",
    "X1 = df_maanshan.drop(columns=['平均负荷','碳排放强度', '日期'])\n",
    "y1 = df_maanshan['碳排放强度']\n",
    "\n",
    "scaler1 = MinMaxScaler()\n",
    "scaler2 = MinMaxScaler()\n",
    "scaler3 = MinMaxScaler()\n",
    "scaler4 = MinMaxScaler()\n",
    "X1_suzhou_scaled = scaler1.fit_transform(X1_suzhou)\n",
    "y1_suzhou_scaled = scaler2.fit_transform(y1_suzhou.to_frame())\n",
    "X1_scaled = scaler3.fit_transform(X1)\n",
    "y1_scaled = scaler4.fit_transform(y1.to_frame())\n",
    "\n",
    "y1_suzhou_scaled=pd.Series(y1_suzhou_scaled.flatten())\n",
    "y1_scaled=pd.Series(y1_scaled.flatten())\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1_scaled, y1_scaled, test_size=0.3, random_state=42)\n",
    "X1_train=np.vstack((X1_suzhou_scaled,X1_train))\n",
    "y1_train=np.hstack((y1_suzhou_scaled,y1_train))\n",
    "y1_test_recover=scaler4.inverse_transform(pd.DataFrame(y1_test))"
   ],
   "id": "81cf8d1ee6664190",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Sorted feature importance",
   "id": "8c600136cfa3a696"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_feature_importance(feature_importances):\n",
    "    sorted_idx = np.argsort(feature_importances)\n",
    "    sorted_feature_names = np.array(X1.columns)[sorted_idx]\n",
    "    sorted_feature_importances = feature_importances[sorted_idx]\n",
    "    sorted_correlations = df_maanshan.corr()['碳排放强度'].drop('碳排放强度')[sorted_idx]\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    bars = plt.barh(sorted_feature_names, sorted_feature_importances,height = 0.6,color=np.where(sorted_correlations > 0, '#CA7373', '#4874CB'))\n",
    "    plt.yticks(fontsize=13, fontweight='bold')\n",
    "    plt.xticks(fontsize=13, fontweight='bold')\n",
    "    plt.xlabel(\"特征重要性\", fontsize=13, fontweight='bold')\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "    plt.show()"
   ],
   "id": "b1384c3a3cd3822f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Prediction result graph",
   "id": "8942aa5f65162a8d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_line(pred):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.lines as mlines  # 导入 mlines\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei']  # 使用黑体 SimHei\n",
    "    plt.rcParams['axes.unicode_minus'] = False    # 解决负号显示问题\n",
    "    plt.figure(figsize=(9, 5))\n",
    "    plt.plot(pred, label='预测值', linewidth=1,color = \"#4874CB\")       # 添加预测值的标签\n",
    "    plt.plot(y1_test_recover, label='实际值', linewidth=1, color='#CA7373')  # 添加真实值的标签\n",
    "    plt.scatter(range(len(pred)), pred, label='预测值',  alpha=0.7,marker= \"X\",color = \"#4874CB\")  # 绘制预测值的散点图\n",
    "    plt.scatter(range(len(y1_test_recover)), y1_test_recover, label='实际值', alpha=0.7, color='#CA7373')  # 绘制真实值的散点图\n",
    "    line1 = mlines.Line2D([], [], color=\"#4874CB\", marker=\"X\", markersize=6, label=\"预测值\")\n",
    "    line2 = mlines.Line2D([], [], color=\"#CA7373\", marker=\"o\", markersize=6, label=\"实际值\")\n",
    "    \n",
    "    plt.legend(handles=[line1, line2], fontsize=12.5)\n",
    "    plt.xlabel(\"样本序列\",fontsize = 15,fontweight='bold')\n",
    "    plt.ylabel(\"碳排放强度/(g/kWh)\",fontsize = 15,fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()  # 调整布局，确保所有元素不重叠\n",
    "    # plt.savefig(\"rf1.png\",dpi=500,bbox_inches='tight')\n",
    "    plt.show()"
   ],
   "id": "61aa665bd8e0dc55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Comparison between the predicted value and the true value",
   "id": "65f3c515e15354df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_compare_line(pred,r2):\n",
    "    z = np.polyfit(y1_test_recover.T[0], pred, 1)  # 线性拟合\n",
    "    p = np.poly1d(z)  # 得到拟合的多项式函数\n",
    "    y_fit = p(y1_test_recover.T[0])\n",
    "    residuals = pred - y_fit\n",
    "    std_err = np.std(residuals)\n",
    "    confidence_interval = 1.96 * std_err  # 95%置信区间对应的倍数是1.96\n",
    "    data = pd.DataFrame({'y_test': y1_test_recover.T[0], 'y_pred': pred, 'y_fit': y_fit})\n",
    "    data_sorted = data.sort_values(by='y_test')\n",
    "    sorted_y_test = data_sorted['y_test'].values\n",
    "    sorted_y_pred = data_sorted['y_pred'].values\n",
    "    sorted_y_fit = data_sorted['y_fit'].values\n",
    "    plt.scatter(sorted_y_test, sorted_y_pred, color='blue', alpha=0.6, edgecolor='k', label='Data point')\n",
    "    plt.plot(sorted_y_test, sorted_y_fit, color='orange', alpha=0.6, label=f\"Fit line\\n$R^2$ = {r2:.2f}\")\n",
    "    plt.fill_between(sorted_y_test, sorted_y_fit - confidence_interval, sorted_y_fit + confidence_interval, color='orange', alpha=0.2, label='95% Confidence interval')\n",
    "    max_val = max(sorted_y_test.max(), sorted_y_pred.max())  # 找到最大值，确保参考线绘制完整\n",
    "    min_val = min(sorted_y_test.min(), sorted_y_pred.min())  # 找到最小值\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='y = x')  # 画出y=x的对角线\n",
    "    plt.title(\"Comparison of model predictions with real values\", fontsize=14)\n",
    "    plt.xlabel(\"Real values of CEI / (g/kWh)\", fontsize=14)\n",
    "    plt.ylabel(\"Predictions of CEI / (g/kWh)\", fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "e80ee20353a4c19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1.SVM",
   "id": "f29beca2197e1c2c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "svr_model = SVR(gamma=0.005,C=4600,epsilon=0.09)\n",
    "svr_model.fit(X1_train, y1_train)\n",
    "svm_y_pred = svr_model.predict(X1_test)\n",
    "\n",
    "svm_y_pred=scaler4.inverse_transform(pd.DataFrame({'pred':svm_y_pred}))\n",
    "y1_test_recover=scaler4.inverse_transform(pd.DataFrame(y1_test))\n",
    "svm_mse = mean_squared_error(y1_test_recover, svm_y_pred)\n",
    "svm_rmse = np.sqrt(svm_mse)\n",
    "svm_mae = mean_absolute_error(y1_test_recover, svm_y_pred)\n",
    "svm_mape = mean_absolute_percentage_error(y1_test_recover, svm_y_pred)\n",
    "svm_r2 = r2_score(y1_test_recover, svm_y_pred)\n",
    "\n",
    "print(f\"svm_MSE: {svm_mse:.6f}\")\n",
    "print(f\"svm_RMSE: {svm_rmse:.6f}\")\n",
    "print(f\"svm_MAE: {svm_mae:.6f}\")\n",
    "print(f\"svm_MAPE: {svm_mape*100:.6f}\")\n",
    "print(f\"svm_R Square: {svm_r2:.6f}\")"
   ],
   "id": "4ec6d445ced29913",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot_feature_importance(np.abs(svr_model.coef_).flatten())\n",
    "plot_compare_line(svm_y_pred.T[0],svm_r2)\n",
    "plot_line(svm_y_pred)"
   ],
   "id": "e1a52aa8b08ecbca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''import shap\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 使用黑体 SimHei\n",
    "plt.rcParams['axes.unicode_minus'] = False    # 解决负号显示问题\n",
    "# Use the trained SVR model to create an explainer\n",
    "explainer = shap.KernelExplainer(svr_model.predict, X1_train)\n",
    "# Calculate SHAP values for the test set\n",
    "shap_values = explainer.shap_values(X1_test)\n",
    "# Visualize feature importance using SHAP\n",
    "shap.summary_plot(shap_values, X1_test, feature_names=X1.columns)'''"
   ],
   "id": "c664469c8cc08e94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_X1_train=pd.DataFrame(X1_train,columns=X1.columns)",
   "id": "61eb7d63981c0021",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def pianYiLai(f1,f2,s1,s2):\n",
    "    from sklearn.inspection import PartialDependenceDisplay\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    t2_features3 = [f1, f2,(f1,f2)]\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei']  # 使用黑体 SimHei\n",
    "    plt.rcParams['axes.unicode_minus'] = False    # 解决负号显示问题\n",
    "    # 生成双向部分依赖图\n",
    "    disp = PartialDependenceDisplay.from_estimator(svr_model, X1, t2_features3)\n",
    "\n",
    "    disp.axes_.ravel()[0].set_ylabel('偏依赖量/(g/kWh)', fontsize=13, fontweight='bold')  # Set y-axis label and make it bold\n",
    "    disp.axes_.ravel()[2].set_ylabel(s2, fontsize=13, fontweight='bold')  # Set y-axis label and make it bold\n",
    "    disp.axes_.ravel()[0].set_xlabel(s1, fontsize=13, fontweight='bold')  # Set y-axis label and make it bold\n",
    "    disp.axes_.ravel()[1].set_xlabel(s2, fontsize=13, fontweight='bold')  # Set y-axis label and make it bold\n",
    "    disp.axes_.ravel()[2].set_xlabel(s1, fontsize=13, fontweight='bold')  # Set y-axis label and make it bold\n",
    "    plt.subplots_adjust(wspace=0.7)\n",
    "\n",
    "    # Save the plot to an image file\n",
    "    #plt.savefig('partial_dependence_plot3.png', dpi=1000, bbox_inches='tight')  # Save as PNG with 500 dpi\n",
    "    plt.show()"
   ],
   "id": "ab0ace88ffe6eb88",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# pianYiLai('负荷率','排烟温度','负荷率平均值(%)','排烟温度/°C')",
   "id": "c14852b1261069fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2.RF",
   "id": "10b9633d6b1d1c9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "correlation_matrix = df_maanshan.drop(columns=['排汽温度', '日期']).corr()\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(n_jobs=28,max_depth=26,n_estimators=178,random_state=42)\n",
    "rf_model.fit(X1_train, y1_train)\n",
    "rf_y1_pred = rf_model.predict(X1_test)\n",
    "\n",
    "rf_y1_pred=scaler4.inverse_transform(pd.DataFrame({'pred':rf_y1_pred}))\n",
    "# y1_test_recover=scaler4.inverse_transform(pd.DataFrame(y1_test))\n",
    "\n",
    "rf_mse = mean_squared_error(y1_test_recover, rf_y1_pred)\n",
    "rf_rmse = np.sqrt(rf_mse)  # Calculating RMSE\n",
    "rf_mae = mean_absolute_error(y1_test_recover, rf_y1_pred)\n",
    "rf_mape = mean_absolute_percentage_error(y1_test_recover, rf_y1_pred)\n",
    "rf_r2 = r2_score(y1_test_recover, rf_y1_pred)\n",
    "\n",
    "print(f\"rf_MSE: {rf_mse:.6f}\")\n",
    "print(f\"rf_RMSE: {rf_rmse:.6f}\")\n",
    "print(f\"rf_MAE: {rf_mae:.6f}\")\n",
    "print(f\"rf_MAPE: {rf_mape*100:.6f}\")\n",
    "print(f\"rf_R Square: {rf_r2:.6f}\")"
   ],
   "id": "44d6fc16522afea6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_feature_importance(rf_model.feature_importances_)\n",
    "plot_compare_line(rf_y1_pred.T[0],rf_r2)\n",
    "plot_line(rf_y1_pred)"
   ],
   "id": "acf8882743cb3d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3.XGB",
   "id": "b0fcc06b3b55e6f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from xgboost import XGBRegressor\n",
    "# 初始化XGBoost回归器\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=48,        # 树的数量\n",
    "    max_depth=7,             # 树的最大深度\n",
    "    learning_rate=0.1,       # 学习率\n",
    "    subsample=0.8,           # 每棵树使用的样本比例\n",
    "    colsample_bytree=0.8,    # 每棵树使用的特征比例\n",
    "    random_state=42\n",
    ")\n",
    "# 训练模型\n",
    "xgb_model.fit(X1_train, y1_train)\n",
    "# Predict on the test set\n",
    "xgb_y1_pred =  xgb_model.predict(X1_test)\n",
    "xgb_y1_pred=scaler4.inverse_transform(pd.DataFrame({'pred':xgb_y1_pred}))\n",
    "# y1_test_recover=scaler4.inverse_transform(pd.DataFrame(y1_test))\n",
    "# Evaluate the model\n",
    "xgb_mse = mean_squared_error(y1_test_recover, xgb_y1_pred)\n",
    "xgb_rmse = np.sqrt(xgb_mse)  # Calculating RMSE\n",
    "xgb_mae = mean_absolute_error(y1_test_recover, xgb_y1_pred)\n",
    "xgb_mape = mean_absolute_percentage_error(y1_test_recover, xgb_y1_pred)\n",
    "xgb_r2 = r2_score(y1_test_recover, xgb_y1_pred)\n",
    "print(f\"xgb_MSE: {xgb_mse:.6f}\")\n",
    "print(f\"xgb_RMSE: {xgb_rmse:.6f}\")\n",
    "print(f\"xgb_MAE: {xgb_mae:.6f}\")\n",
    "print(f\"xgb_MAPE: {xgb_mape*100:.6f}\")\n",
    "print(f\"xgb_R Square: {xgb_r2:.6f}\")"
   ],
   "id": "de712fde84ede14f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_feature_importance(xgb_model.feature_importances_)\n",
    "plot_compare_line(xgb_y1_pred.T[0],xgb_r2)\n",
    "plot_line(xgb_y1_pred)"
   ],
   "id": "c501f74be45190bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4.LR",
   "id": "646b9e1ac2a99792"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# 创建线性回归模型\n",
    "linear_model = LinearRegression()\n",
    "# 拟合模型\n",
    "linear_model.fit(X1_train, y1_train)\n",
    "# 在测试集上进行预测\n",
    "linear_y1_pred = linear_model.predict(X1_test)\n",
    "linear_y1_pred=scaler4.inverse_transform(pd.DataFrame({'pred':linear_y1_pred}))\n",
    "# y1_test_recover=scaler4.inverse_transform(pd.DataFrame(y1_test))\n",
    "lr_mse = mean_squared_error(y1_test_recover, linear_y1_pred)\n",
    "lr_rmse = np.sqrt(xgb_mse)  # Calculating RMSE\n",
    "lr_mae = mean_absolute_error(y1_test_recover, linear_y1_pred)\n",
    "lr_mape = mean_absolute_percentage_error(y1_test_recover, linear_y1_pred)\n",
    "lr_r2 = r2_score(y1_test_recover, linear_y1_pred)\n",
    "print(f\"lr_MSE: {lr_mse:.6f}\")\n",
    "print(f\"lr_RMSE: {lr_rmse:.6f}\")\n",
    "print(f\"lr_MAE: {lr_mae:.6f}\")\n",
    "print(f\"lr_MAPE: {lr_mape*100:.6f}\")\n",
    "print(f\"lr_R Square: {lr_r2:.6f}\")\n",
    "print(f\"回归系数: {linear_model.coef_}\")\n",
    "print(f\"截距: {linear_model.intercept_}\")"
   ],
   "id": "1bae4b5a5c3389ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_feature_importance(np.abs(linear_model.coef_).flatten())\n",
    "plot_compare_line(linear_y1_pred.T[0],lr_r2)\n",
    "plot_line(linear_y1_pred)"
   ],
   "id": "64364ae5331021f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "5.DNN",
   "id": "b2baadf3a222be4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "device='cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "X1_train_tensor=torch.FloatTensor(X1_train).to(device)\n",
    "y1_train_tensor=torch.FloatTensor(y1_train).view(-1,1).to(device)\n",
    "X1_test_tensor=torch.FloatTensor(X1_test).to(device)\n",
    "y1_test_tensor=torch.FloatTensor(y1_test).view(-1,1).to(device)\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)  # 第一个隐藏层\n",
    "        self.fc2 = nn.Linear(64, 32)          # 第二个隐藏层\n",
    "        self.fc3 = nn.Linear(32, 1)           # 输出层\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# 初始化模型\n",
    "input_size = X1_train.shape[1]\n",
    "model = SimpleNN(input_size).to(device)\n",
    "# 3. 定义损失函数和优化器\n",
    "criterion = nn.MSELoss().to(device)  # 均方误差损失\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.12)\n",
    "\n",
    "# 4. 训练模型\n",
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 设定训练模式\n",
    "    optimizer.zero_grad()  # 梯度清零\n",
    "    outputs = model(X1_train_tensor)  # 前向传播\n",
    "    loss = criterion(outputs, y1_train_tensor)  # 计算损失\n",
    "    loss.backward()  # 反向传播\n",
    "    optimizer.step()  # 更新权重\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 5. 评估模型\n",
    "model.eval()  # 切换到评估模式\n",
    "with torch.no_grad():\n",
    "    predictions = model(X1_test_tensor)  # 预测\n",
    "    test_loss = criterion(predictions, y1_test_tensor)  # 计算测试损失\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')\n",
    "\n",
    "predictions=predictions.cpu().numpy().flatten()\n",
    "predictions=scaler4.inverse_transform(pd.DataFrame({'pred':predictions}))\n",
    "# Evaluate the model\n",
    "dnn_mse = mean_squared_error(y1_test_recover, predictions)\n",
    "dnn_rmse = np.sqrt(dnn_mse)  # Calculating RMSE\n",
    "dnn_mae = mean_absolute_error(y1_test_recover, predictions)\n",
    "dnn_mape = mean_absolute_percentage_error(y1_test_recover, predictions)\n",
    "dnn_r2 = r2_score(y1_test_recover, predictions)\n",
    "print(f\"dnn_MSE: {dnn_mse:.6f}\")\n",
    "print(f\"dnn_RMSE: {dnn_rmse:.6f}\")\n",
    "print(f\"dnn_MAE: {dnn_mae:.6f}\")\n",
    "print(f\"dnn_MAPE: {dnn_mape*100:.6f}\")\n",
    "print(f\"dnn_R Square: {dnn_r2:.6f}\")"
   ],
   "id": "f6d7492a3c38d1fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot_feature_importance(model.)\n",
    "plot_compare_line(predictions.T[0],dnn_r2)\n",
    "plot_line(predictions)"
   ],
   "id": "ec3d2256f990178d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
